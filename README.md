# Machine-Learning-Metabolic-Syndrome

Machine learning in the context of healthcare is thought to grow to USD 67.4 billion industry by 2027, through the application of revolutionizing clinical decisions and making diagnosis through the use of models and artificial intelligence: with many start-ups entering and exploring this space currently through various software solutions. Too explore the possibilities of this growing industry we set out to explore and compare various machine learning models both (1) supervised models, such as Na誰ve Bayes and logistic regression against (2) unsupervised models such as k-means clustering and principal component analysis with k-means clustering applied as a form of dimension reduction. Through a search of the literature we were unable to find any previous studies which compared and contrasted supervised learning against unsupervised in the context of metabolic syndrome, though similar studies have been applied in the context of diabetes with mixed results. A major limitation in our comparison is that by employing certain assumptions in our unsupervised learning algorithm we resulted in a loss of non-clinical binary features, thus reducing our ability to compare our models. The objective of this study was to find a model with both high accuracy and sensitivity and compare the models against one another. We tend to found that overall accuracy of 80% was common amongst all our machine learning models, both supervised and unsupervised and suggests the predictive power of machine learning in the context of healthcare. Furthermore, through fine tunning our models through the application of assumption testing we where able to produce a model with almost 85% sensitivity, an important indicator of success used in the application of healthcare, without further compromising accuracy and specificity. It was observed that the payoff in improvement of our indicators tend to dimmish as we applied more data scientific methodologies to improve our models and meet as many assumptions as possible, with unpredictable changes such as improving and worsening some key indicators. Overall, this study found that in the application of machine learning is somewhat promising in the application of diagnosing metabolic syndrome and suggests the possibility of one day being incorporated into healthcare given the sheer amount of future investment in this space. 

# Findings

The purpose of this paper was to compare and contrast the application of machine learning models to the diagnosis of metabolic syndrome, this was achieved by developing various supervised and unsupervised models and looking at key indicators such as (1) accuracy, (2) sensitivity, (3) specificity and (4) AUC if applicable to the model, and in addition highlight any limitations and issues faced when developing models. One major limitation which should be highlighted is the reduction and removal of features from the unsupervised learning model to ensure satisfying assumptions, meaning our unsupervised learning method and supervised learning method was built and developed based on different features, making the comparison between the two limited. This further highlight that when developing a machine learning model that it is important to test assumptions and consider many variations of the same model as part of the refinements process. It is thought and proposed here that when refining a model the payoff in improvement will diminish, and can even impact the model in a negative way evident in the literature previously sighted. We observed that when trying to increase assumption uptake that our models did not always lead to improvements, or the improvement was dimished and impacted another measure negatively.

When comparing which supervised method to elect, we would suggest a model with high sensitivity, accuracy and AUC, furthermore we would want a model which satisfies the most assumptions possible and a model which attempts to minimise bias. From table 2, table 3 and the discussion above we know that the logistic models were embed with violations, even though logistic 4 had the best AUC value as seen in table 3 (AUC 0.8277), for this reason of multiple violations we would not recommend employing a logistic regression for predicting diagnosis. Instead, we know From table NUMBER our Na誰ve Bayes model 2 had the highest sensitivity of 0.87, though an issue with this model was it was not adjusted for the unbalanced nature of the data set, thus incorporating bias into our model; for this reason and the violation of multicollinearity we would not recommend this model, instead recommend Na誰ve Bayes 4 which satisfies all assumptions, and accounts for the unbalanced nature of the data set, allowing us to comment further on the improved accuracy value.  
	
Whilst PCA is a tool employed as a form of dimension reduction prior to commencing k-means clustering, in the aspect of our models it resulted in a 16.25% reduction in accuracy relative to our generic k-means clustering model. Despite the accuracy and specificity increasing when applying PCA, our key indicator is heavily focused on maximising specificity, and given the large percentage reduction we would not recommend this model for that resson. Furthermore, we were able to review the output of the mean value of each predictor for each class, and as expected there was a clear distinction between the mean values between each group which is consistent with the literature. 

In summary, it is evident that our supervised learning algorithm was superior, with a recommendation of employing the Na誰ve Bayes model relative to logstic and the unsuerpvised learning. A major benefit of the supervised learning is we where able to incorporate both clinical and non-clinical features, as well as allowing for categorical features which are also thought to be related to metabolic syndrome such as economic status, race and even martial status. This paper overall found that machine learning in the application of healthcare yielded promising preliminary results given that accuracy tended to exceed 80% and sensitivity was also consistently around 80-85% in most models produced, and would warrant further investigation about developing and implements other models, or adjusting the models developed here. In addition, we would also recommend obtaining a larger sample, preferably a sample with a better balance of data if possible and apply an unsupervised learning method which can accommodate categorical variables which would allow us to better compare and contrast unsupervised against the supervised models. In addition, future studies would also benefit from incorporating more features 
